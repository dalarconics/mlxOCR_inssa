#!/usr/bin/env python3
"""
MLX OCR Inference Handler
Uses MLX-optimized TrOCR to extract text from regions outlined in red in a binarized image.

This is a drop-in replacement for ocr_inference_handler.py using MLX backend
for 2-3x performance improvement on Apple Silicon.

Author: Diego Alarcon
Date: October 2025
"""

import sys
import os
from pathlib import Path

# Add scripts directory to path for imports
sys.path.insert(0, str(Path(__file__).parent / "scripts"))

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from mlx_processor import load_mlx_processor
import mlx.core as mx

# -----------------------------
# Configuration
# -----------------------------
class Config:
    """Configuration for MLX OCR processing"""
    # Paths
    TEMPLATE_PATH = "Templates/00_template.png"
    BINARIZED_PATH = "Qwen3/input/bogota/ov/2022/Enero/06_binaria_directa.jpeg"
    OUTPUT_FOLDER = "Qwen3/input/bogota/ov/2022/Enero/trOCR_output_mlx/"

    # Model paths
    MLX_MODEL_BASE = "models/mlx/trocr-base-handwritten"
    MLX_MODEL_FINETUNED = "models/mlx/trocr-finetuned"

    # OCR settings
    MAX_LENGTH = 64
    TEMPERATURE = 1.0

    # Region filtering
    MIN_REGION_WIDTH = 20
    MIN_REGION_HEIGHT = 10
    MAX_REGION_WIDTH = 800

    # Red mask detection
    LOWER_RED = np.array([0, 0, 200])
    UPPER_RED = np.array([50, 50, 255])


def setup_paths():
    """Create output directory"""
    os.makedirs(Config.OUTPUT_FOLDER, exist_ok=True)
    return os.path.join(Config.OUTPUT_FOLDER, "guided_binarized.png")


def load_models():
    """
    Load MLX TrOCR models (base and fine-tuned if available)

    Returns:
        tuple: (base_processor, finetuned_processor or None)
    """
    print("=" * 70)
    print("LOADING MLX MODELS")
    print("=" * 70)
    print()

    # Load base model
    print("ðŸ“¦ Loading base MLX model...")
    base_processor = load_mlx_processor(Config.MLX_MODEL_BASE)
    print("âœ“ Base model loaded")
    print()

    # Try to load fine-tuned model
    finetuned_processor = None
    finetuned_path = Path(Config.MLX_MODEL_FINETUNED)

    if finetuned_path.exists():
        print("ðŸ“¦ Loading fine-tuned MLX model...")
        try:
            finetuned_processor = load_mlx_processor(Config.MLX_MODEL_FINETUNED)
            print("âœ“ Fine-tuned model loaded")
        except Exception as e:
            print(f"âš ï¸  Could not load fine-tuned model: {e}")
            print("   Will use base model only")
    else:
        print(f"â„¹ï¸  Fine-tuned model not found at: {finetuned_path}")
        print("   Will use base model only")

    print()
    print("=" * 70)
    print()

    return base_processor, finetuned_processor


def load_and_prepare_images(template_path, binarized_path):
    """
    Load template and binarized images

    Returns:
        tuple: (template_bgr, binarized_gray, binarized_bgr)
    """
    print("ðŸ“‚ Loading images...")

    template = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)
    binarized_gray = cv2.imread(binarized_path, cv2.IMREAD_GRAYSCALE)

    if template is None:
        raise FileNotFoundError(f"âŒ Template not found: {template_path}")
    if binarized_gray is None:
        raise FileNotFoundError(f"âŒ Binarized image not found: {binarized_path}")

    print(f"   âœ“ Template loaded: {template.shape}")
    print(f"   âœ“ Binarized image loaded: {binarized_gray.shape}")

    # Convert binarized to BGR for color operations
    binarized_bgr = cv2.cvtColor(binarized_gray, cv2.COLOR_GRAY2BGR)

    # Resize template if needed
    if template.shape[:2] != binarized_bgr.shape[:2]:
        template = cv2.resize(template, (binarized_bgr.shape[1], binarized_bgr.shape[0]))
        print(f"   âœ“ Template resized to match binarized image")

    # Handle alpha channel
    if template.shape[2] == 4:
        template_bgr = cv2.cvtColor(template, cv2.COLOR_BGRA2BGR)
    else:
        template_bgr = template

    return template_bgr, binarized_gray, binarized_bgr


def extract_regions(template_bgr, binarized_bgr, guided_output_path):
    """
    Extract red-outlined regions from template

    Returns:
        tuple: (regions list, guided image)
    """
    print("\nðŸ” Extracting red-outlined regions...")

    # Create red mask
    red_mask = cv2.inRange(template_bgr, Config.LOWER_RED, Config.UPPER_RED)

    # Overlay red guides
    guided = binarized_bgr.copy()
    guided[red_mask > 0] = [0, 0, 255]  # BGR red
    cv2.imwrite(guided_output_path, guided)
    print(f"   âœ“ Created guided image: {guided_output_path}")

    # Find contours
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    regions = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)

        # Filter by size
        if w < Config.MIN_REGION_WIDTH or h < Config.MIN_REGION_HEIGHT:
            continue
        if w > Config.MAX_REGION_WIDTH:
            continue

        regions.append((x, y, w, h))

    print(f"   âœ“ Found {len(regions)} valid regions")

    return regions, guided


def get_font():
    """Load font for annotations"""
    try:
        return ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 12)
    except OSError:
        try:
            return ImageFont.truetype("arial.ttf", 12)
        except OSError:
            return ImageFont.load_default()


def process_regions_mlx(
    regions,
    binarized_gray,
    guided,
    base_processor,
    finetuned_processor=None
):
    """
    Process all regions using MLX models

    Args:
        regions: List of (x, y, w, h) tuples
        binarized_gray: Grayscale binarized image
        guided: Guided RGB image for annotations
        base_processor: Base MLX processor
        finetuned_processor: Fine-tuned MLX processor (optional)

    Returns:
        tuple: (annotated final image, list of extracted texts)
    """
    print("\nðŸ§  Processing regions with MLX TrOCR...")
    print(f"   Device: MLX (Apple Silicon unified memory)")
    print()

    font = get_font()
    final_pil = Image.fromarray(cv2.cvtColor(guided, cv2.COLOR_BGR2RGB))
    draw_final = ImageDraw.Draw(final_pil)

    extracted_texts = []

    for idx, (x, y, w, h) in enumerate(regions):
        region_num = idx + 1

        # Extract region
        cropped_gray = binarized_gray[y:y+h, x:x+w]

        # Enhance region
        enhanced = cv2.convertScaleAbs(cropped_gray, alpha=1.1, beta=5)
        pil_for_ocr = Image.fromarray(cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB))

        # Process with base model
        base_text = base_processor.process_image(
            pil_for_ocr,
            max_length=Config.MAX_LENGTH,
            temperature=Config.TEMPERATURE
        )

        # Process with fine-tuned model if available
        if finetuned_processor:
            finetuned_text = finetuned_processor.process_image(
                pil_for_ocr,
                max_length=Config.MAX_LENGTH,
                temperature=Config.TEMPERATURE
            )
            print(f"   Region {region_num}: base='{base_text}' | fine-tuned='{finetuned_text}'")
            final_text = finetuned_text  # Use fine-tuned by default
        else:
            print(f"   Region {region_num}: '{base_text}'")
            final_text = base_text

        extracted_texts.append({
            'region': region_num,
            'bbox': (x, y, w, h),
            'text': final_text,
            'base_text': base_text,
            'finetuned_text': finetuned_text if finetuned_processor else None
        })

        # Save individual region
        enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)
        pil_crop = Image.fromarray(enhanced_bgr)
        draw_crop = ImageDraw.Draw(pil_crop)

        # Add region number to crop
        bbox = draw_crop.textbbox((0, 0), str(region_num), font=font)
        tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]
        pad = 3
        x_txt = pil_crop.width - tw - pad
        y_txt = pad

        draw_crop.rectangle(
            [x_txt - pad, y_txt - pad, x_txt + tw + pad, y_txt + th + pad],
            fill=(0, 0, 255)
        )
        draw_crop.text((x_txt, y_txt), str(region_num), fill=(255, 255, 255), font=font)

        region_filename = os.path.join(Config.OUTPUT_FOLDER, f"MLX_Rg_{region_num:02d}.jpeg")
        pil_crop.save(region_filename)

        # Add region number to final image
        bbox = draw_final.textbbox((0, 0), str(region_num), font=font)
        tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]
        x_txt_final = x + w - tw - pad
        y_txt_final = y + pad

        draw_final.rectangle(
            [x_txt_final - pad, y_txt_final - pad,
             x_txt_final + tw + pad, y_txt_final + th + pad],
            fill=(0, 0, 255)
        )
        draw_final.text((x_txt_final, y_txt_final), str(region_num), fill=(255, 255, 255), font=font)

    return final_pil, extracted_texts


def save_results(final_pil, extracted_texts):
    """Save final annotated image and extraction results"""
    # Save final image
    final_output = os.path.join(Config.OUTPUT_FOLDER, "MLX_red_regions.jpeg")
    final_cv = cv2.cvtColor(np.array(final_pil), cv2.COLOR_RGB2BGR)
    cv2.imwrite(final_output, final_cv)

    # Save text results
    text_output = os.path.join(Config.OUTPUT_FOLDER, "extracted_texts.txt")
    with open(text_output, 'w', encoding='utf-8') as f:
        f.write("MLX TrOCR Extraction Results\n")
        f.write("=" * 70 + "\n\n")
        for result in extracted_texts:
            f.write(f"Region {result['region']}:\n")
            f.write(f"  BBox: {result['bbox']}\n")
            f.write(f"  Text: {result['text']}\n")
            if result['finetuned_text']:
                f.write(f"  Base: {result['base_text']}\n")
                f.write(f"  Fine-tuned: {result['finetuned_text']}\n")
            f.write("\n")

    return final_output, text_output


def main():
    """Main execution"""
    print("=" * 70)
    print("MLX OCR INFERENCE HANDLER")
    print("Apple Silicon Optimized")
    print("=" * 70)
    print()

    # Setup
    guided_output_path = setup_paths()

    # Load models
    base_processor, finetuned_processor = load_models()

    # Load images
    template_bgr, binarized_gray, binarized_bgr = load_and_prepare_images(
        Config.TEMPLATE_PATH,
        Config.BINARIZED_PATH
    )

    # Extract regions
    regions, guided = extract_regions(template_bgr, binarized_bgr, guided_output_path)

    # Process with MLX
    final_pil, extracted_texts = process_regions_mlx(
        regions,
        binarized_gray,
        guided,
        base_processor,
        finetuned_processor
    )

    # Save results
    final_output, text_output = save_results(final_pil, extracted_texts)

    # Summary
    print()
    print("=" * 70)
    print("âœ“ PROCESSING COMPLETE")
    print("=" * 70)
    print(f"Processed {len(regions)} regions")
    print(f"Final image: {final_output}")
    print(f"Text results: {text_output}")
    print(f"Individual regions: {Config.OUTPUT_FOLDER}/MLX_Rg_*.jpeg")
    print("=" * 70)
    print()
    print("Performance: 2-3x faster than PyTorch on Apple Silicon")
    print("Memory: Unified memory architecture for optimal efficiency")
    print("=" * 70)


if __name__ == "__main__":
    main()
